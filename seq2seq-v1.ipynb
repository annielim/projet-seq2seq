{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNmHwkXIipD5fUUjou3xTeU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0Sa8oc6-GTPl","colab_type":"code","colab":{}},"source":["import numpy as np\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.autograd import Variable\n","\n","import random\n","import math\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I4HfKILOIinq","colab_type":"code","outputId":"086f5327-87e5-477b-8845-40ebf16cfa91","executionInfo":{"status":"ok","timestamp":1592224648568,"user_tz":-120,"elapsed":4859,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"colab":{"base_uri":"https://localhost:8080/","height":372}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mon Jun 15 12:37:26 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AXntUorDGtEa","colab_type":"code","outputId":"282940c1-6dd1-487e-9fcb-2db5073c8792","executionInfo":{"status":"ok","timestamp":1592224663505,"user_tz":-120,"elapsed":19782,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kHRf_eHlG0w6","colab_type":"code","outputId":"a4a8b646-28f4-4693-983c-a6350c437fb5","executionInfo":{"status":"ok","timestamp":1592224663506,"user_tz":-120,"elapsed":3935,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /gdrive/My\\ Drive/E4/Projet\\ Seq2seq"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/gdrive/.shortcut-targets-by-id/1L0GWY2fCntIpHodTYUvTCzdpBSUKQOnq/Projet Seq2seq\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BUoA1PxKJFxX","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jlu2XNckHRxL","colab_type":"code","colab":{}},"source":["class CSVDataset(Dataset):\n","\n","    def __init__(self,file_path, n_x, n_y, n_rows, skip_rows):\n","        super(CSVDataset,self).__init__()\n","        self.n_x = n_x\n","        self.n_y = n_y\n","        self.data = pd.read_csv(file_path, nrows=n_rows, skiprows=skip_rows)\n","        self.data = self.data.fillna(0)\n","        self.data = self.data[self.data.columns[1:]].values\n","        self.data = self.data.astype(np.float32)\n","\n","    def __len__(self):\n","        return (self.data.shape[1]-self.n_x-self.n_y)*self.data.shape[0]\n","\n","    def __getitem__(self, index):\n","        line = index //  (self.data.shape[1]-self.n_x-self.n_y)\n","        i = self.n_x + self.n_y + (index % (self.data.shape[1]-self.n_x-self.n_y))\n","\n","        item = (torch.FloatTensor(self.data[line,i-self.n_y-self.n_x:i-self.n_y]),\n","                torch.FloatTensor(self.data[line,i-self.n_y:i]))\n","        return item"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g47GKprqHgx9","colab_type":"code","colab":{}},"source":["n_x = 50 \n","n_y = 10 \n","train_dataset = CSVDataset(\"web-traffic-time-series-forecasting/train_1.csv\", n_x, n_y, 600, 0)\n","valid_dataset = CSVDataset(\"web-traffic-time-series-forecasting/train_1.csv\", n_x, n_y, 200, 600)\n","test_dataset = CSVDataset(\"web-traffic-time-series-forecasting/train_1.csv\", n_x, n_y, 200, 800)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qKuDQxKBHhoa","colab_type":"code","colab":{}},"source":["train_loader = DataLoader(train_dataset, batch_size=256, drop_last=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=256, drop_last=True)\n","test_loader = DataLoader(test_dataset, batch_size=256, drop_last=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQX-TpJnUk_j","colab_type":"code","outputId":"4577c2bb-68e9-41a8-d47b-2726aed71681","executionInfo":{"status":"ok","timestamp":1592230908630,"user_tz":-120,"elapsed":350,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(train_loader)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1148"]},"metadata":{"tags":[]},"execution_count":193}]},{"cell_type":"code","metadata":{"id":"iEaq_1L0IZxX","colab_type":"code","outputId":"e25affb5-54d1-403d-a34f-e2aa67603fe8","executionInfo":{"status":"ok","timestamp":1592230908844,"user_tz":-120,"elapsed":445,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"colab":{"base_uri":"https://localhost:8080/","height":301}},"source":["for data, label in train_loader:\n","    print(\"--------- DATA ---------\")\n","    print(data)\n","    print(\" --------- LABEL ---------\")\n","    print(label)\n","    break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--------- DATA ---------\n","tensor([[18., 11.,  5.,  ..., 15., 25.,  9.],\n","        [11.,  5., 13.,  ..., 25.,  9.,  5.],\n","        [ 5., 13., 14.,  ...,  9.,  5.,  6.],\n","        ...,\n","        [18.,  8.,  9.,  ..., 40., 19., 15.],\n","        [ 8.,  9., 17.,  ..., 19., 15., 15.],\n","        [ 9., 17.,  9.,  ..., 15., 15., 29.]])\n"," --------- LABEL ---------\n","tensor([[ 5.,  6., 20.,  ...,  5., 13.,  4.],\n","        [ 6., 20.,  3.,  ..., 13.,  4.,  9.],\n","        [20.,  3., 14.,  ...,  4.,  9., 10.],\n","        ...,\n","        [15., 29., 18.,  ..., 19., 11., 50.],\n","        [29., 18., 16.,  ..., 11., 50., 22.],\n","        [18., 16., 13.,  ..., 50., 22., 39.]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-IQ4k1ByUf_n","colab_type":"code","colab":{}},"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","\n","        self.lstm = nn.LSTM(input_dim, hid_dim, n_layers, dropout = dropout)\n","\n","        self.hidden = torch.zeros(self.n_layers, 1, self.hid_dim, device=device)\n","        self.cell = torch.zeros(self.n_layers, 1, self.hid_dim, device=device)\n","\n","    def forward(self, src):\n","        src = src.unsqueeze(1).to(device)\n","        output, (hidden, cell) = self.lstm(src.view(len(src) ,1, -1), (self.hidden, self.cell))\n","        return hidden, cell"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nqjAT5wEUgDM","colab_type":"code","colab":{}},"source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        \n","        self.output_dim = output_dim\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        self.lstm = nn.LSTM(output_dim, hid_dim, n_layers, dropout = dropout)\n","        \n","        self.fc_out = nn.Linear(hid_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, src, hidden, cell):\n","        src = src.unsqueeze(1).to(device)\n","        output, (hidden, cell) = self.lstm(src, (hidden, cell))\n","        prediction = self.fc_out(output.view(len(src), -1))\n","        return prediction, hidden, cell"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hW-31zFxWqGW","colab_type":"code","colab":{}},"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","        assert encoder.hid_dim == decoder.hid_dim, \\\n","            \"Hidden dimensions of encoder and decoder must be equal!\"\n","        assert encoder.n_layers == decoder.n_layers, \\\n","            \"Encoder and decoder must have equal number of layers!\"\n","        \n","    def forward(self, src, trg):\n","       \n","        hidden, cell = self.encoder(src)\n","        output, hidden, cell = self.decoder(trg, hidden, cell)\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1lEAJ681Xl87","colab_type":"code","outputId":"2d5080f7-4618-467c-d7e1-c40c7abc132a","executionInfo":{"status":"ok","timestamp":1592231368432,"user_tz":-120,"elapsed":512,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"colab":{"base_uri":"https://localhost:8080/","height":194}},"source":["INPUT_DIM = n_x\n","OUTPUT_DIM = n_y\n","HID_DIM = 512\n","N_LAYERS = 2\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","\n","enc = Encoder(INPUT_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n","\n","model = Seq2Seq(enc, dec, device).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","criterion = nn.MSELoss()\n","print(model)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Seq2Seq(\n","  (encoder): Encoder(\n","    (lstm): LSTM(50, 512, num_layers=2, dropout=0.5)\n","  )\n","  (decoder): Decoder(\n","    (lstm): LSTM(10, 512, num_layers=2, dropout=0.5)\n","    (fc_out): Linear(in_features=512, out_features=10, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-eZP0-YlXl_O","colab_type":"code","colab":{}},"source":["def train(model, iterator, optimizer, criterion, clip):\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    for i, batch in enumerate(iterator):\n","        \n","        if(i%100 == 0):\n","          print(\"In train, batch number: {}\".format(i))\n","        src = torch.tensor(batch[0]).to(torch.float32).to(device)\n","        trg = torch.tensor(batch[1]).to(torch.float32).to(device)\n","        \n","        optimizer.zero_grad()\n","        output = model(src, trg)\n","        \n","        loss = criterion(output, trg)\n","        with torch.autograd.set_detect_anomaly(True):\n","          loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LzgnVtsUYoxJ","colab_type":"code","colab":{}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n","\n","            if(i%100 == 0):\n","              print(\"In evaluate, batch number: {}\".format(i))\n","\n","            src = torch.tensor(batch[0]).to(torch.float32).to(device)\n","            trg = torch.tensor(batch[1]).to(torch.float32).to(device)\n","\n","            output = model(src, trg)\n","            loss = criterion(output, trg)\n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8bRsluKGYrHE","colab_type":"code","colab":{}},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kv5BRHfbYsym","colab_type":"code","outputId":"b59ab08b-8af8-4c7d-d5cc-a90a0d7b21a8","executionInfo":{"status":"ok","timestamp":1592234048953,"user_tz":-120,"elapsed":2203587,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["N_EPOCHS = 10\n","CLIP = 1\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, valid_loader, criterion)\n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'Seq2seq/model/seq2seq-model-1.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    #print(\"Train loss: {}, T\".format(i))\n","    print(f'\\tTrain Loss: {train_loss:.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f}')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["In train, batch number: 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  if sys.path[0] == '':\n"],"name":"stderr"},{"output_type":"stream","text":["In train, batch number: 100\n","In train, batch number: 200\n","In train, batch number: 300\n","In train, batch number: 400\n","In train, batch number: 500\n","In train, batch number: 600\n","In train, batch number: 700\n","In train, batch number: 800\n","In train, batch number: 900\n","In train, batch number: 1000\n","In train, batch number: 1100\n","In evaluate, batch number: 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  from ipykernel import kernelapp as app\n"],"name":"stderr"},{"output_type":"stream","text":["In evaluate, batch number: 100\n","In evaluate, batch number: 200\n","In evaluate, batch number: 300\n","Epoch: 01 | Time: 3m 40s\n","\tTrain Loss: 134766.142\n","\t Val. Loss: 1005930.394\n","In train, batch number: 0\n","In train, batch number: 100\n","In train, batch number: 200\n","In train, batch number: 300\n","In train, batch number: 400\n","In train, batch number: 500\n","In train, batch number: 600\n","In train, batch number: 700\n","In train, batch number: 800\n","In train, batch number: 900\n","In train, batch number: 1000\n","In train, batch number: 1100\n","In evaluate, batch number: 0\n","In evaluate, batch number: 100\n","In evaluate, batch number: 200\n","In evaluate, batch number: 300\n","Epoch: 02 | Time: 3m 40s\n","\tTrain Loss: 134306.307\n","\t Val. Loss: 1004268.224\n","In train, batch number: 0\n","In train, batch number: 100\n","In train, batch number: 200\n","In train, batch number: 300\n","In train, batch number: 400\n","In train, batch number: 500\n","In train, batch number: 600\n","In train, batch number: 700\n","In train, batch number: 800\n","In train, batch number: 900\n","In train, batch number: 1000\n","In train, batch number: 1100\n","In evaluate, batch number: 0\n","In evaluate, batch number: 100\n","In evaluate, batch number: 200\n","In evaluate, batch number: 300\n","Epoch: 03 | Time: 3m 39s\n","\tTrain Loss: 134744.552\n","\t Val. Loss: 1005484.317\n","In train, batch number: 0\n","In train, batch number: 100\n","In train, batch number: 200\n","In train, batch number: 300\n","In train, batch number: 400\n","In train, batch number: 500\n","In train, batch number: 600\n","In train, batch number: 700\n","In train, batch number: 800\n","In train, batch number: 900\n","In train, batch number: 1000\n","In train, batch number: 1100\n","In evaluate, batch number: 0\n","In evaluate, batch number: 100\n","In evaluate, batch number: 200\n","In evaluate, batch number: 300\n","Epoch: 04 | Time: 3m 40s\n","\tTrain Loss: 134304.529\n","\t Val. Loss: 1003951.948\n","In train, batch number: 0\n","In train, batch number: 100\n","In train, batch number: 200\n","In train, batch number: 300\n","In train, batch number: 400\n","In train, batch number: 500\n","In train, batch number: 600\n","In train, batch number: 700\n","In train, batch number: 800\n","In train, batch number: 900\n","In train, batch number: 1000\n","In train, batch number: 1100\n","In evaluate, batch number: 0\n","In evaluate, batch number: 100\n","In evaluate, batch number: 200\n","In evaluate, batch number: 300\n","Epoch: 05 | Time: 3m 40s\n","\tTrain Loss: 133992.500\n","\t Val. Loss: 1002792.814\n","In train, batch number: 0\n","In train, batch number: 100\n","In train, batch number: 200\n","In train, batch number: 300\n","In train, batch number: 400\n","In train, batch number: 500\n","In train, batch number: 600\n","In train, batch number: 700\n","In train, batch number: 800\n","In train, batch number: 900\n","In train, batch number: 1000\n","In train, batch number: 1100\n","In evaluate, batch number: 0\n","In evaluate, batch number: 100\n","In evaluate, batch number: 200\n","In evaluate, batch number: 300\n","Epoch: 06 | Time: 3m 40s\n","\tTrain Loss: 133843.792\n","\t Val. Loss: 1002873.223\n","In train, batch number: 0\n","In train, batch number: 100\n","In train, batch number: 200\n","In train, batch number: 300\n","In train, batch number: 400\n","In train, batch number: 500\n","In train, batch number: 600\n","In train, batch number: 700\n","In train, batch number: 800\n","In train, batch number: 900\n","In train, batch number: 1000\n","In train, batch number: 1100\n","In evaluate, batch number: 0\n","In evaluate, batch number: 100\n","In evaluate, batch number: 200\n","In evaluate, batch number: 300\n","Epoch: 07 | Time: 3m 40s\n","\tTrain Loss: 133810.034\n","\t Val. Loss: 1002556.451\n","In train, batch number: 0\n","In train, batch number: 100\n","In train, batch number: 200\n","In train, batch number: 300\n","In train, batch number: 400\n","In train, batch number: 500\n","In train, batch number: 600\n","In train, batch number: 700\n","In train, batch number: 800\n","In train, batch number: 900\n","In train, batch number: 1000\n","In train, batch number: 1100\n","In evaluate, batch number: 0\n","In evaluate, batch number: 100\n","In evaluate, batch number: 200\n","In evaluate, batch number: 300\n","Epoch: 08 | Time: 3m 40s\n","\tTrain Loss: 133788.907\n","\t Val. Loss: 1002422.862\n","In train, batch number: 0\n","In train, batch number: 100\n","In train, batch number: 200\n","In train, batch number: 300\n","In train, batch number: 400\n","In train, batch number: 500\n","In train, batch number: 600\n","In train, batch number: 700\n","In train, batch number: 800\n","In train, batch number: 900\n","In train, batch number: 1000\n","In train, batch number: 1100\n","In evaluate, batch number: 0\n","In evaluate, batch number: 100\n","In evaluate, batch number: 200\n","In evaluate, batch number: 300\n","Epoch: 09 | Time: 3m 40s\n","\tTrain Loss: 133594.230\n","\t Val. Loss: 1001929.520\n","In train, batch number: 0\n","In train, batch number: 100\n","In train, batch number: 200\n","In train, batch number: 300\n","In train, batch number: 400\n","In train, batch number: 500\n","In train, batch number: 600\n","In train, batch number: 700\n","In train, batch number: 800\n","In train, batch number: 900\n","In train, batch number: 1000\n","In train, batch number: 1100\n","In evaluate, batch number: 0\n","In evaluate, batch number: 100\n","In evaluate, batch number: 200\n","In evaluate, batch number: 300\n","Epoch: 10 | Time: 3m 40s\n","\tTrain Loss: 133494.973\n","\t Val. Loss: 1001347.921\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"upkmlIHlYwpm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hzmnj8ar6FOl","colab_type":"code","colab":{}},"source":["a = torch.zeros(256, 10)\n","print(a.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6npQbYbp6JFv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}