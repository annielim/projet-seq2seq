{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq2seq-v2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0Sa8oc6-GTPl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592808227442,"user_tz":-120,"elapsed":3970,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}}},"source":["import numpy as np\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.autograd import Variable\n","\n","import random\n","import math\n","import time"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"I4HfKILOIinq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":372},"executionInfo":{"status":"ok","timestamp":1592808229830,"user_tz":-120,"elapsed":6343,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"8f5bcf01-bab6-456c-8a46-b8645a57db3c"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mon Jun 22 06:43:45 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AXntUorDGtEa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1592808247956,"user_tz":-120,"elapsed":24456,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"a7299c22-a293-4323-8853-f27247d141f6"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kHRf_eHlG0w6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592808249884,"user_tz":-120,"elapsed":692,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"094c150f-8e8e-40d5-b348-24823608c2ac"},"source":["%cd /gdrive/My\\ Drive/E4/Projet\\ Seq2seq"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/gdrive/.shortcut-targets-by-id/1L0GWY2fCntIpHodTYUvTCzdpBSUKQOnq/Projet Seq2seq\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BUoA1PxKJFxX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592808250779,"user_tz":-120,"elapsed":1339,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jlu2XNckHRxL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592808250780,"user_tz":-120,"elapsed":1108,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}}},"source":["class CSVDataset(Dataset):\n","\n","    def __init__(self, file_path, n_x, n_y, n_rows, skip_rows):\n","        super(CSVDataset,self).__init__()\n","        self.n_x = n_x\n","        self.n_y = n_y\n","        temp_data = pd.read_csv(file_path, nrows=n_rows, skiprows=skip_rows)\n","        temp_titles = temp_data[temp_data.columns[:1]].values\n","        temp_data = temp_data[temp_data.columns[1:]].values\n","        \n","        \n","        truth_table = np.isnan(temp_data)\n","        number_nan_row = 0\n","        nan_row_id = []\n","        for index, row in enumerate(truth_table):\n","          if (row[0] == True):\n","            number_nan_row += 1\n","            nan_row_id.append(index)\n","\n","        self.data = []\n","        self.titles = []\n","        for index, row in enumerate(temp_data):\n","          if index in nan_row_id:\n","            continue\n","          else:\n","            self.data.append(row)\n","            self.titles.append(temp_titles[index])\n","        \n","        nan_index = np.argwhere(np.isnan(self.data))\n","        for x, y in nan_index:\n","          self.data[x][y] = np.nanmean(self.data, dtype=np.float32)\n","\n","        self.data = np.array(self.data)\n","\n","        print(self.data.shape)\n","\n","    def __len__(self):\n","        return (self.data.shape[1]-self.n_x-self.n_y)*self.data.shape[0]\n","\n","    def __getitem__(self, index):\n","        line = index //  (self.data.shape[1]-self.n_x-self.n_y)\n","        i = self.n_x + self.n_y + (index % (self.data.shape[1]-self.n_x-self.n_y))\n","\n","        \"\"\" \n","        data = [] \n","        for row, title in enumerate(self.titles):\n","          title_split = title[0].split('_')\n","          for col, value in enumerate(self.data[row]):\n","            data[row][col] = [value, title_split[-3].split('.')[0], title_split[-2], title_split[-1]]\n","        \"\"\"\n","\n","        item = (torch.FloatTensor(self.data[line,i-self.n_y-self.n_x:i-self.n_y]),\n","                torch.FloatTensor(self.data[line,i-self.n_y:i]))\n","        return item"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"g47GKprqHgx9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1592808253726,"user_tz":-120,"elapsed":3517,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"2dfa815d-894c-48da-ef2c-5180ca2309b5"},"source":["n_x = 50 \n","n_y = 2\n","train_dataset = CSVDataset(\"web-traffic-time-series-forecasting/train_1.csv\", n_x, n_y, 600, 0)\n","valid_dataset = CSVDataset(\"web-traffic-time-series-forecasting/train_1.csv\", n_x, n_y, 200, 600)\n","test_dataset = CSVDataset(\"web-traffic-time-series-forecasting/train_1.csv\", n_x, n_y, 200, 800)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["(535, 550)\n","(200, 550)\n","(200, 550)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qKuDQxKBHhoa","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592808253727,"user_tz":-120,"elapsed":3060,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}}},"source":["train_loader = DataLoader(train_dataset, batch_size=256, drop_last=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=256, drop_last=True)\n","test_loader = DataLoader(test_dataset, batch_size=256, drop_last=True)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQX-TpJnUk_j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592808256667,"user_tz":-120,"elapsed":1264,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"99f65247-b4ab-4c78-a455-66da6b3d1cc1"},"source":["len(train_loader)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1040"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"iEaq_1L0IZxX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592808256668,"user_tz":-120,"elapsed":994,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"4706e6c8-f17e-4e60-ef06-568f077f63b2"},"source":["for data, label in train_loader:\n","    print(\"--------- DATA ---------\")\n","    print(data)\n","    print(\" --------- LABEL ---------\")\n","    print(label)\n","    break"],"execution_count":10,"outputs":[{"output_type":"stream","text":["--------- DATA ---------\n","tensor([[18., 11.,  5.,  ..., 15., 25.,  9.],\n","        [11.,  5., 13.,  ..., 25.,  9.,  5.],\n","        [ 5., 13., 14.,  ...,  9.,  5.,  6.],\n","        ...,\n","        [18.,  8.,  9.,  ..., 40., 19., 15.],\n","        [ 8.,  9., 17.,  ..., 19., 15., 15.],\n","        [ 9., 17.,  9.,  ..., 15., 15., 29.]])\n"," --------- LABEL ---------\n","tensor([[  5.,   6.],\n","        [  6.,  20.],\n","        [ 20.,   3.],\n","        [  3.,  14.],\n","        [ 14.,  46.],\n","        [ 46.,   5.],\n","        [  5.,   5.],\n","        [  5.,  13.],\n","        [ 13.,   4.],\n","        [  4.,   9.],\n","        [  9.,  10.],\n","        [ 10.,   9.],\n","        [  9.,  11.],\n","        [ 11.,  11.],\n","        [ 11.,  11.],\n","        [ 11.,   9.],\n","        [  9.,  15.],\n","        [ 15.,   5.],\n","        [  5.,  10.],\n","        [ 10.,   7.],\n","        [  7.,   4.],\n","        [  4.,   8.],\n","        [  8.,   9.],\n","        [  9.,  10.],\n","        [ 10.,   6.],\n","        [  6.,  13.],\n","        [ 13.,  16.],\n","        [ 16.,   6.],\n","        [  6.,  24.],\n","        [ 24.,   9.],\n","        [  9.,  11.],\n","        [ 11.,  12.],\n","        [ 12.,   8.],\n","        [  8.,  14.],\n","        [ 14.,   6.],\n","        [  6.,   6.],\n","        [  6.,  11.],\n","        [ 11.,  14.],\n","        [ 14.,   6.],\n","        [  6.,  10.],\n","        [ 10.,  20.],\n","        [ 20.,   7.],\n","        [  7.,  15.],\n","        [ 15.,   8.],\n","        [  8.,  15.],\n","        [ 15.,   5.],\n","        [  5.,   8.],\n","        [  8.,   8.],\n","        [  8.,   5.],\n","        [  5.,  11.],\n","        [ 11., 165.],\n","        [165.,  34.],\n","        [ 34.,   6.],\n","        [  6.,  13.],\n","        [ 13.,   8.],\n","        [  8.,   9.],\n","        [  9.,  11.],\n","        [ 11.,  26.],\n","        [ 26.,  18.],\n","        [ 18.,   3.],\n","        [  3.,   5.],\n","        [  5.,  12.],\n","        [ 12.,   6.],\n","        [  6.,  16.],\n","        [ 16.,  19.],\n","        [ 19.,   9.],\n","        [  9.,  10.],\n","        [ 10.,  11.],\n","        [ 11.,  11.],\n","        [ 11.,   7.],\n","        [  7.,   9.],\n","        [  9.,  10.],\n","        [ 10.,  24.],\n","        [ 24.,   6.],\n","        [  6.,   6.],\n","        [  6.,   8.],\n","        [  8.,  16.],\n","        [ 16.,  13.],\n","        [ 13.,  10.],\n","        [ 10.,  10.],\n","        [ 10.,   6.],\n","        [  6.,   5.],\n","        [  5.,  20.],\n","        [ 20.,   6.],\n","        [  6.,  47.],\n","        [ 47.,   9.],\n","        [  9.,   9.],\n","        [  9.,  12.],\n","        [ 12.,  11.],\n","        [ 11.,  17.],\n","        [ 17.,  15.],\n","        [ 15.,  14.],\n","        [ 14.,  11.],\n","        [ 11.,  97.],\n","        [ 97.,  11.],\n","        [ 11.,  12.],\n","        [ 12.,  11.],\n","        [ 11.,  14.],\n","        [ 14.,  15.],\n","        [ 15.,  12.],\n","        [ 12., 104.],\n","        [104.,   5.],\n","        [  5.,  22.],\n","        [ 22.,  45.],\n","        [ 45.,  75.],\n","        [ 75.,  29.],\n","        [ 29.,  34.],\n","        [ 34.,  20.],\n","        [ 20.,  12.],\n","        [ 12.,  25.],\n","        [ 25.,   9.],\n","        [  9.,  62.],\n","        [ 62.,  20.],\n","        [ 20.,  19.],\n","        [ 19.,   8.],\n","        [  8.,  23.],\n","        [ 23.,  13.],\n","        [ 13.,  16.],\n","        [ 16.,  34.],\n","        [ 34.,  36.],\n","        [ 36.,  11.],\n","        [ 11.,  18.],\n","        [ 18.,  12.],\n","        [ 12.,  24.],\n","        [ 24.,  30.],\n","        [ 30.,  27.],\n","        [ 27.,  44.],\n","        [ 44.,  35.],\n","        [ 35.,  53.],\n","        [ 53.,  11.],\n","        [ 11.,  26.],\n","        [ 26.,  13.],\n","        [ 13.,  18.],\n","        [ 18.,   9.],\n","        [  9.,  16.],\n","        [ 16.,   6.],\n","        [  6.,  19.],\n","        [ 19.,  20.],\n","        [ 20.,  19.],\n","        [ 19.,  22.],\n","        [ 22.,  30.],\n","        [ 30.,  14.],\n","        [ 14.,  16.],\n","        [ 16.,  22.],\n","        [ 22.,  15.],\n","        [ 15.,  15.],\n","        [ 15.,  26.],\n","        [ 26.,  16.],\n","        [ 16.,  13.],\n","        [ 13.,  27.],\n","        [ 27.,  18.],\n","        [ 18.,  13.],\n","        [ 13.,  32.],\n","        [ 32.,  31.],\n","        [ 31.,  16.],\n","        [ 16.,  38.],\n","        [ 38.,  18.],\n","        [ 18.,   9.],\n","        [  9.,  14.],\n","        [ 14.,  10.],\n","        [ 10.,  24.],\n","        [ 24.,   8.],\n","        [  8.,  15.],\n","        [ 15.,  18.],\n","        [ 18.,  10.],\n","        [ 10.,  23.],\n","        [ 23.,  17.],\n","        [ 17.,  11.],\n","        [ 11.,  26.],\n","        [ 26.,  14.],\n","        [ 14.,   8.],\n","        [  8.,  12.],\n","        [ 12.,   9.],\n","        [  9.,  11.],\n","        [ 11.,  34.],\n","        [ 34.,  17.],\n","        [ 17.,  29.],\n","        [ 29.,  11.],\n","        [ 11.,   9.],\n","        [  9.,  14.],\n","        [ 14.,  21.],\n","        [ 21.,  12.],\n","        [ 12.,  11.],\n","        [ 11.,  13.],\n","        [ 13.,  11.],\n","        [ 11.,  13.],\n","        [ 13.,  16.],\n","        [ 16.,  13.],\n","        [ 13.,  19.],\n","        [ 19.,  21.],\n","        [ 21.,  14.],\n","        [ 14.,  11.],\n","        [ 11.,  35.],\n","        [ 35.,  18.],\n","        [ 18.,  42.],\n","        [ 42.,  15.],\n","        [ 15.,   5.],\n","        [  5.,  21.],\n","        [ 21.,  56.],\n","        [ 56.,   9.],\n","        [  9.,  20.],\n","        [ 20.,  17.],\n","        [ 17.,  18.],\n","        [ 18.,   8.],\n","        [  8.,   9.],\n","        [  9.,  17.],\n","        [ 17.,   9.],\n","        [  9.,  10.],\n","        [ 10.,  14.],\n","        [ 14.,  17.],\n","        [ 17.,   6.],\n","        [  6.,  18.],\n","        [ 18.,  13.],\n","        [ 13.,  11.],\n","        [ 11.,  12.],\n","        [ 12.,  11.],\n","        [ 11.,   8.],\n","        [  8.,  15.],\n","        [ 15.,  11.],\n","        [ 11.,  20.],\n","        [ 20.,  59.],\n","        [ 59.,  11.],\n","        [ 11.,  18.],\n","        [ 18.,  17.],\n","        [ 17.,  12.],\n","        [ 12.,  14.],\n","        [ 14.,  13.],\n","        [ 13.,   9.],\n","        [  9., 490.],\n","        [490., 189.],\n","        [189., 102.],\n","        [102.,  38.],\n","        [ 38., 126.],\n","        [126.,  71.],\n","        [ 71.,  21.],\n","        [ 21.,  57.],\n","        [ 57.,  79.],\n","        [ 79.,  17.],\n","        [ 17.,  17.],\n","        [ 17.,  23.],\n","        [ 23.,  16.],\n","        [ 16.,  23.],\n","        [ 23.,  18.],\n","        [ 18.,  22.],\n","        [ 22.,  44.],\n","        [ 44.,   6.],\n","        [  6.,  31.],\n","        [ 31.,  17.],\n","        [ 17.,  25.],\n","        [ 25.,  40.],\n","        [ 40.,  19.],\n","        [ 19.,  15.],\n","        [ 15.,  15.],\n","        [ 15.,  29.],\n","        [ 29.,  18.],\n","        [ 18.,  16.]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-IQ4k1ByUf_n","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592808256669,"user_tz":-120,"elapsed":772,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}}},"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, hid_dim, n_layers, dropout=0):\n","        super().__init__()\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","\n","        self.lstm = nn.LSTM(input_dim, hid_dim, n_layers, dropout = dropout)\n","        self.softplus = nn.Softplus()\n","\n","        self.hidden = torch.zeros(self.n_layers, 1, self.hid_dim, device=device)\n","        self.cell = torch.zeros(self.n_layers, 1, self.hid_dim, device=device)\n","\n","    def forward(self, src):\n","        src = src.unsqueeze(1).to(device)\n","        output, (hidden, cell) = self.lstm(src.view(len(src) ,1, -1), (self.hidden, self.cell))\n","        hidden = self.softplus(hidden)\n","        return hidden, cell"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"nqjAT5wEUgDM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592808256854,"user_tz":-120,"elapsed":706,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}}},"source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, hid_dim, n_layers, dropout=0):\n","        super().__init__()\n","        \n","        self.output_dim = output_dim\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        self.lstm = nn.LSTM(output_dim, hid_dim, n_layers, dropout = dropout)\n","        self.softplus = nn.Softplus()\n","        self.linear = nn.Linear(hid_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, src, hidden, cell):\n","        src = src.unsqueeze(1).to(device)\n","        output, (hidden, cell) = self.lstm(src, (hidden, cell))\n","        prediction = self.softplus(output.view(len(src), -1))\n","        prediction = self.linear(prediction)\n","        return prediction, hidden, cell"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"hW-31zFxWqGW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592808257458,"user_tz":-120,"elapsed":1083,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}}},"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","        assert encoder.hid_dim == decoder.hid_dim, \\\n","            \"Hidden dimensions of encoder and decoder must be equal!\"\n","        assert encoder.n_layers == decoder.n_layers, \\\n","            \"Encoder and decoder must have equal number of layers!\"\n","        \n","    def forward(self, src, trg):\n","       \n","        hidden, cell = self.encoder(src)\n","        output, hidden, cell = self.decoder(trg, hidden, cell)\n","        return output"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"1lEAJ681Xl87","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":230},"executionInfo":{"status":"ok","timestamp":1592808266201,"user_tz":-120,"elapsed":9608,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"cfba3b3c-526b-44b2-de6d-0f2d165346bf"},"source":["INPUT_DIM = n_x\n","OUTPUT_DIM = n_y\n","HID_DIM = 512\n","N_LAYERS = 2\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","\n","enc = Encoder(INPUT_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n","\n","model = Seq2Seq(enc, dec, device).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","criterion = nn.MSELoss()\n","print(model)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Seq2Seq(\n","  (encoder): Encoder(\n","    (lstm): LSTM(50, 512, num_layers=2, dropout=0.5)\n","    (softplus): Softplus(beta=1, threshold=20)\n","  )\n","  (decoder): Decoder(\n","    (lstm): LSTM(2, 512, num_layers=2, dropout=0.5)\n","    (softplus): Softplus(beta=1, threshold=20)\n","    (linear): Linear(in_features=512, out_features=2, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-eZP0-YlXl_O","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592808266203,"user_tz":-120,"elapsed":9380,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}}},"source":["def train(model, iterator, optimizer, criterion, clip):\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    for i, batch in enumerate(iterator):\n","        \n","        if(i%100 == 0):\n","          print(\"In train, batch number: {}\".format(i))\n","        src = torch.tensor(batch[0]).to(torch.float32).to(device)\n","        trg = torch.tensor(batch[1]).to(torch.float32).to(device)\n","        \n","        optimizer.zero_grad()\n","        output = model(src, trg)\n","        \n","        loss = criterion(output, trg)\n","        with torch.autograd.set_detect_anomaly(True):\n","          loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"LzgnVtsUYoxJ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592808266203,"user_tz":-120,"elapsed":8755,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n","\n","            if(i%100 == 0):\n","              print(\"In evaluate, batch number: {}\".format(i))\n","\n","            src = torch.tensor(batch[0]).to(torch.float32).to(device)\n","            trg = torch.tensor(batch[1]).to(torch.float32).to(device)\n","\n","            output = model(src, trg)\n","            loss = criterion(output, trg)\n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"8bRsluKGYrHE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592808266204,"user_tz":-120,"elapsed":8251,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}}},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"kv5BRHfbYsym","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":885},"executionInfo":{"status":"error","timestamp":1592809822997,"user_tz":-120,"elapsed":239136,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"e44ed88d-a62c-46c9-e1fb-aa7612f477f3"},"source":["N_EPOCHS = 10\n","CLIP = 1\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, valid_loader, criterion)\n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'Seq2seq/model/seq2seq-model-1.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    #print(\"Train loss: {}, T\".format(i))\n","    print(f'\\tTrain Loss: {train_loss:.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f}')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["In train, batch number: 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  if sys.path[0] == '':\n"],"name":"stderr"},{"output_type":"stream","text":["In train, batch number: 100\n","In train, batch number: 200\n","In train, batch number: 300\n","In train, batch number: 400\n","In train, batch number: 500\n","In train, batch number: 600\n","In train, batch number: 700\n","In train, batch number: 800\n","In train, batch number: 900\n","In train, batch number: 1000\n","In evaluate, batch number: 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  from ipykernel import kernelapp as app\n"],"name":"stderr"},{"output_type":"stream","text":["In evaluate, batch number: 100\n","In evaluate, batch number: 200\n","In evaluate, batch number: 300\n","Epoch: 01 | Time: 3m 30s\n","\tTrain Loss: 150891.277\n","\t Val. Loss: 998649.467\n","In train, batch number: 0\n","In train, batch number: 100\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-164d4e1d56bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-3fffa7901f35>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"upkmlIHlYwpm","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1592808267947,"user_tz":-120,"elapsed":8903,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r5B4NHPQQvkG","colab_type":"code","colab":{}},"source":["data = pd.read_csv(\"web-traffic-time-series-forecasting/train_1.csv\", nrows=100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ivgzCjbfBQ9Z","colab_type":"code","colab":{}},"source":["data.head"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gH2ICIGjBWuC","colab_type":"code","colab":{}},"source":["temp_data = data[data.columns[:1]].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-YixPpvTBnA5","colab_type":"code","colab":{}},"source":["temp_data[0][0].split('_')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"675cLgAtBoUE","colab_type":"code","colab":{}},"source":["for elem in temp_data:\n","  lst = elem[0].split('_')\n","  print(lst[-3].split('.')[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fZ_yUsinDCB8","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}