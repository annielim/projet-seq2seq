{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq2seq-v2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0Sa8oc6-GTPl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594052055723,"user_tz":-120,"elapsed":4209,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}}},"source":["import numpy as np\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.autograd import Variable\n","\n","import random\n","import math\n","import time"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"I4HfKILOIinq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":372},"executionInfo":{"status":"ok","timestamp":1594052059166,"user_tz":-120,"elapsed":7583,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"ae696c58-22db-4ddd-bd89-a5a0632aa279"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mon Jul  6 16:14:15 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   65C    P8    12W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AXntUorDGtEa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1594052077063,"user_tz":-120,"elapsed":25467,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"3c20a726-f7fe-411a-b334-3da57c018aa6"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kHRf_eHlG0w6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594052077065,"user_tz":-120,"elapsed":25456,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"685e0076-691c-4dcc-e66a-df7e87d651fe"},"source":["%cd /gdrive/My\\ Drive/E4/Projet\\ Seq2seq"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/gdrive/.shortcut-targets-by-id/1L0GWY2fCntIpHodTYUvTCzdpBSUKQOnq/Projet Seq2seq\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BUoA1PxKJFxX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594052077585,"user_tz":-120,"elapsed":25973,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jlu2XNckHRxL","colab_type":"code","colab":{}},"source":["class CSVDataset(Dataset):\n","\n","    def __init__(self, file_path, n_x, n_y, n_rows, skip_rows):\n","        super(CSVDataset,self).__init__()\n","        self.n_x = n_x\n","        self.n_y = n_y\n","        temp_data = pd.read_csv(file_path, nrows=n_rows, skiprows=skip_rows)\n","        temp_titles = temp_data[temp_data.columns[:1]].values\n","        temp_data = temp_data[temp_data.columns[1:]].values\n","        \n","        \n","        truth_table = np.isnan(temp_data)\n","        number_nan_row = 0\n","        nan_row_id = []\n","        for index, row in enumerate(truth_table):\n","          if (row[0] == True):\n","            number_nan_row += 1\n","            nan_row_id.append(index)\n","\n","        self.data = []\n","        self.titles = []\n","        for index, row in enumerate(temp_data):\n","          if index in nan_row_id:\n","            continue\n","          else:\n","            self.data.append(row)\n","            self.titles.append(temp_titles[index])\n","        \n","        nan_index = np.argwhere(np.isnan(self.data))\n","        for x, y in nan_index:\n","          self.data[x][y] = np.nanmean(self.data, dtype=np.float32)\n","\n","        self.data = np.array(self.data)\n","\n","        print(self.data.shape)\n","\n","    def __len__(self):\n","        return (self.data.shape[1]-self.n_x-self.n_y)*self.data.shape[0]\n","\n","    def __getitem__(self, index):\n","        line = index //  (self.data.shape[1]-self.n_x-self.n_y)\n","        i = self.n_x + self.n_y + (index % (self.data.shape[1]-self.n_x-self.n_y))\n","\n","        \"\"\" \n","        data = [] \n","        for row, title in enumerate(self.titles):\n","          title_split = title[0].split('_')\n","          for col, value in enumerate(self.data[row]):\n","            data[row][col] = [value, title_split[-3].split('.')[0], title_split[-2], title_split[-1]]\n","        \"\"\"\n","\n","        item = (torch.FloatTensor(self.data[line,i-self.n_y-self.n_x:i-self.n_y]),\n","                torch.FloatTensor(self.data[line,i-self.n_y:i]))\n","        return item"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g47GKprqHgx9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1593180020638,"user_tz":-120,"elapsed":24601,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"8e677220-2225-4c41-9c7d-704434ca6dd5"},"source":["n_x = 50 \n","n_y = 2\n","train_dataset = CSVDataset(\"web-traffic-time-series-forecasting/train_1.csv\", n_x, n_y, 600, 0)\n","valid_dataset = CSVDataset(\"web-traffic-time-series-forecasting/train_1.csv\", n_x, n_y, 200, 600)\n","test_dataset = CSVDataset(\"web-traffic-time-series-forecasting/train_1.csv\", n_x, n_y, 200, 800)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(535, 550)\n","(200, 550)\n","(200, 550)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qKuDQxKBHhoa","colab_type":"code","colab":{}},"source":["train_loader = DataLoader(train_dataset, batch_size=256, drop_last=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=256, drop_last=True)\n","test_loader = DataLoader(test_dataset, batch_size=256, drop_last=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQX-TpJnUk_j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593180025962,"user_tz":-120,"elapsed":739,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"9d94ece3-e6d9-4f99-a429-258b80d97b3f"},"source":["len(train_loader)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1040"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"DQoSgDK77fsK","colab_type":"code","colab":{}},"source":["for data, label in train_loader:\n","    print(\"--------- DATA ---------\")\n","    print(data)\n","    print(\" --------- LABEL ---------\")\n","    print(label)\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iEaq_1L0IZxX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1593180113745,"user_tz":-120,"elapsed":421,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"16c2fab0-686d-42ed-d39e-1f0acfb812a3"},"source":["for data, label in train_loader:\n","    print(\"Données : {}\".format(data[0]))\n","    print(\"Label : {}\".format(label[0]))\n","    break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Données : tensor([18., 11.,  5., 13., 14.,  9.,  9., 22., 26., 24., 19., 10., 14., 15.,\n","         8., 16.,  8.,  8., 16.,  7., 11., 10., 20., 18., 15., 14., 49., 10.,\n","        16., 18.,  8.,  5.,  9.,  7., 13.,  9.,  7.,  4., 11., 10.,  5.,  9.,\n","         9.,  9.,  9., 13.,  4., 15., 25.,  9.])\n","Label : tensor([5., 6.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-IQ4k1ByUf_n","colab_type":"code","colab":{}},"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, hid_dim, n_layers, dropout=0):\n","        super().__init__()\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","\n","        self.lstm = nn.LSTM(input_dim, hid_dim, n_layers, dropout = dropout)\n","        self.softplus = nn.Softplus()\n","\n","        self.hidden = torch.zeros(self.n_layers, 1, self.hid_dim, device=device)\n","        self.cell = torch.zeros(self.n_layers, 1, self.hid_dim, device=device)\n","\n","    def forward(self, src):\n","        src = src.unsqueeze(1).to(device)\n","        output, (hidden, cell) = self.lstm(src.view(len(src) ,1, -1), (self.hidden, self.cell))\n","        hidden = self.softplus(hidden)\n","        return hidden, cell"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nqjAT5wEUgDM","colab_type":"code","colab":{}},"source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, hid_dim, n_layers, dropout=0):\n","        super().__init__()\n","        \n","        self.output_dim = output_dim\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        self.lstm = nn.LSTM(output_dim, hid_dim, n_layers, dropout = dropout)\n","        self.softplus = nn.Softplus()\n","        self.linear = nn.Linear(hid_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, src, hidden, cell):\n","        src = src.unsqueeze(1).to(device)\n","        output, (hidden, cell) = self.lstm(src, (hidden, cell))\n","        prediction = self.softplus(output.view(len(src), -1))\n","        prediction = self.linear(prediction)\n","        return prediction, hidden, cell"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hW-31zFxWqGW","colab_type":"code","colab":{}},"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","        assert encoder.hid_dim == decoder.hid_dim, \\\n","            \"Hidden dimensions of encoder and decoder must be equal!\"\n","        assert encoder.n_layers == decoder.n_layers, \\\n","            \"Encoder and decoder must have equal number of layers!\"\n","        \n","    def forward(self, src, trg):\n","       \n","        hidden, cell = self.encoder(src)\n","        output, hidden, cell = self.decoder(trg, hidden, cell)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1lEAJ681Xl87","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":230},"executionInfo":{"status":"ok","timestamp":1592808266201,"user_tz":-120,"elapsed":9608,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"cfba3b3c-526b-44b2-de6d-0f2d165346bf"},"source":["INPUT_DIM = n_x\n","OUTPUT_DIM = n_y\n","HID_DIM = 512\n","N_LAYERS = 2\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","\n","enc = Encoder(INPUT_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n","\n","model = Seq2Seq(enc, dec, device).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","criterion = nn.MSELoss()\n","print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Seq2Seq(\n","  (encoder): Encoder(\n","    (lstm): LSTM(50, 512, num_layers=2, dropout=0.5)\n","    (softplus): Softplus(beta=1, threshold=20)\n","  )\n","  (decoder): Decoder(\n","    (lstm): LSTM(2, 512, num_layers=2, dropout=0.5)\n","    (softplus): Softplus(beta=1, threshold=20)\n","    (linear): Linear(in_features=512, out_features=2, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-eZP0-YlXl_O","colab_type":"code","colab":{}},"source":["def train(model, iterator, optimizer, criterion, clip):\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    for i, batch in enumerate(iterator):\n","        \n","        if(i%100 == 0):\n","          print(\"In train, batch number: {}\".format(i))\n","        src = torch.tensor(batch[0]).to(torch.float32).to(device)\n","        trg = torch.tensor(batch[1]).to(torch.float32).to(device)\n","        \n","        optimizer.zero_grad()\n","        output = model(src, trg)\n","        \n","        loss = criterion(output, trg)\n","        with torch.autograd.set_detect_anomaly(True):\n","          loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LzgnVtsUYoxJ","colab_type":"code","colab":{}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n","\n","            if(i%100 == 0):\n","              print(\"In evaluate, batch number: {}\".format(i))\n","\n","            src = torch.tensor(batch[0]).to(torch.float32).to(device)\n","            trg = torch.tensor(batch[1]).to(torch.float32).to(device)\n","\n","            output = model(src, trg)\n","            loss = criterion(output, trg)\n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8bRsluKGYrHE","colab_type":"code","colab":{}},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kv5BRHfbYsym","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":885},"executionInfo":{"status":"error","timestamp":1592809822997,"user_tz":-120,"elapsed":239136,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"e44ed88d-a62c-46c9-e1fb-aa7612f477f3"},"source":["N_EPOCHS = 10\n","CLIP = 1\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, valid_loader, criterion)\n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'Seq2seq/model/seq2seq-model-1.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    #print(\"Train loss: {}, T\".format(i))\n","    print(f'\\tTrain Loss: {train_loss:.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["In train, batch number: 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  if sys.path[0] == '':\n"],"name":"stderr"},{"output_type":"stream","text":["In train, batch number: 100\n","In train, batch number: 200\n","In train, batch number: 300\n","In train, batch number: 400\n","In train, batch number: 500\n","In train, batch number: 600\n","In train, batch number: 700\n","In train, batch number: 800\n","In train, batch number: 900\n","In train, batch number: 1000\n","In evaluate, batch number: 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  from ipykernel import kernelapp as app\n"],"name":"stderr"},{"output_type":"stream","text":["In evaluate, batch number: 100\n","In evaluate, batch number: 200\n","In evaluate, batch number: 300\n","Epoch: 01 | Time: 3m 30s\n","\tTrain Loss: 150891.277\n","\t Val. Loss: 998649.467\n","In train, batch number: 0\n","In train, batch number: 100\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-164d4e1d56bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-3fffa7901f35>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"upkmlIHlYwpm","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r5B4NHPQQvkG","colab_type":"code","colab":{}},"source":["data = pd.read_csv(\"web-traffic-time-series-forecasting/train_1.csv\", nrows=100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ivgzCjbfBQ9Z","colab_type":"code","colab":{}},"source":["data.head"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gH2ICIGjBWuC","colab_type":"code","colab":{}},"source":["temp_data = data[data.columns[:1]].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-YixPpvTBnA5","colab_type":"code","colab":{}},"source":["temp_data[0][0].split('_')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"675cLgAtBoUE","colab_type":"code","colab":{}},"source":["for elem in temp_data:\n","  lst = elem[0].split('_')\n","  print(lst[-3].split('.')[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fZ_yUsinDCB8","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHQEAz9B6HfU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594052321254,"user_tz":-120,"elapsed":6088,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}}},"source":["submission = pd.read_csv(\"web-traffic-time-series-forecasting/sample_submission_2.csv\")"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"QZag_3Md6Wag","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1594052321256,"user_tz":-120,"elapsed":2407,"user":{"displayName":"Sébastien ZHOU","photoUrl":"","userId":"11352649297537061669"}},"outputId":"b65c92b0-4abb-46de-9b3e-71ae5fb67c03"},"source":["submission.head"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method NDFrame.head of                    Id  Visits\n","0        0b293039387a       0\n","1        7114389dd824       0\n","2        057b02ff1f09       0\n","3        bd2aca21caa3       0\n","4        c0effb42cdd5       0\n","...               ...     ...\n","8993901  f78fbaa305ad       0\n","8993902  33aecaf259d1       0\n","8993903  a36228b64466       0\n","8993904  26887d3e5c99       0\n","8993905  06ad06979f80       0\n","\n","[8993906 rows x 2 columns]>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"N3K8Q-v36ZyO","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}